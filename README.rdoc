Uses a Facial Recognition API, the Facebook API and FQL, the Twitter API OAuth, Javascript Annotated Time Line ￼￼and Geo Bubble Charts, Sentiment and Demographic Analysis, and Natural Language ￼Understanding (NLU) to deconstruct posts and pictures to map out a variety of factors related to happiness over time and location. Charts out view of world happiness and filters through the posts for learning.

Hooks up to the Bhappy API in order to allow users to view and create posts for language analysis (Natural Language Understanding) on the go, so they can express how they feel at any given time:

https://github.com/dgreenbe77/bhappy-rubymotion-iOS-mobile
