Uses a Facial Recognition API, the Facebook API and FQL, OAuth, Javascript Annotated Time Line ￼￼and Geo Bubble Charts, Sentiment and Demographic Analysis, and Natural Language ￼Understanding (NLU) to deconstruct posts and pictures to map out a variety of factors related to happiness over time and location. Also, it charts out a view of world happiness. Adding a learning aspect with user input.

Hooks up to the Bhappy API in order to allow users to view and create posts for language analysis (Natural Language Understanding) on the go, so they can express how they feel at any given time:

https://github.com/dgreenbe77/bhappy-rubymotion-iOS-mobile
